<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Website for the 5th neural scaling workshop">
    <meta name="author" content="Mohammad">
    <meta http-equiv='cache-control' content='no-cache'> 
    <meta http-equiv='expires' content='0'> 
    <meta http-equiv='pragma' content='no-cache'>
    <title>Emergent Behaviours and Phase Transitions in Deep Learning</title>
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.css" rel="stylesheet">
    <!-- Custom fonts for this template -->
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">
    <!-- Custom styles for this template -->
    <link href="css/grayscale.css" rel="stylesheet">
  </head>
  <body id="page-top">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">Neural Scaling Workshop</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <!-- <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#about">Home</a>
            </li> -->
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#CFC">Call for Papers</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#Speakers">Invited Speakers</a>
            </li>
<!--             <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#Schedule">Schedule</a>
            </li> -->
            <!-- <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#Papers">Papers</a>
            </li> -->
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#Committee">Organizers</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>
    <!-- Header -->
    <header class="masthead">
      <div class="container d-flex h-100 align-items-center">
        <div class="mx-auto text-center">
          <h3 class="text-white-50 mx-auto mt-2 mb-5">5th Neural Scaling Workshop:</h3>
          <h1 class="mx-auto my-0 text-uppercase">Emergent Behaviours and Phase Transitions in Deep Learning</h1><br><br><br>
          <!-- <h2 class="text-white-50 mx-auto mt-2 mb-5"><b><a href="https://nips.cc/Conferences/2019/Schedule?showEvent=13158"> West Exhibition Hall A, Sat Dec 14, 08:00 AM</a></b></h2> -->
          <h2 class="text-white-50 mx-auto mt-2 mb-5">July 28th, Honolulu, Hawaii  </h2>
          <!-- <a href="#CFC" class="btn btn-primary js-scroll-trigger">Call for Papers</a> -->
            <div class = "row">
          <h5 class="text-white-50 mx-auto mt-2 mb-5">
          <!-- We will provide the details of our call for Papers <a href="contributions.html">here</a> soon! <br> -->
          </h5>
            </div>
        </div>
      </div>
    </header>
    <!-- About Section -->
    <section id="about" class="about-section text-center">
      <div class="container">
        <h2 class="text-white mb-4">Overview;</h2>
        <p class="text-white-75">
          The purpose of the workshop is to discuss and foster new ideas and research directions around emergent behaviours and phase transitions in deep learning. In recent years, we have seen many emergent capabilities appear with models at scale, such as in-context learning, reasoning and systematic generalization in language and vision models. On the other hand, even toy models have been found to exhibit sudden changes in their behaviour or performance, as was discovered with the grokking phenomenon and the appearance of induction heads in Transformers. Researchers have studied emergent behaviors using various approaches, including scaling laws, statistical mechanics, and mechanistic interpretability. To aggregate past findings and showcase cutting-edge research in this field, we are holding a workshop on Emergent Behaviors and Phase Transitions of Deep Learning, colocated with the ICML 2023. </p>
        
        <div class="row">
      </section>
      <!-- Projects Section -->
      <section id="Speakers" class="projects-section bg-light">
        <h2 class="text-black mb-4 text-center">Invited Speakers</h2>
        <div class="container">
          <!-- Featured Project Row -->
          <div class="row no-gutters mb-4 mb-lg-5" id="lenka">
            <div class="col-xl-3 col-lg-5">
              <img class="img-fluid mb-0 mb-lg-0" src="img/lenka.jpg" alt="">
            </div>
            <div class="col-xl-9 col-lg-7">
              <div class="featured-text text-center text-lg-left">
                <h4>
                <a href="https://en.wikipedia.org/wiki/Lenka_Zdeborov%C3%A1" class="pagelink">
                   Lenka Zdeborová (EPFL)
                </a></h4>
<!--                 <h5>Title:</h5>
                <p class="text-black-50 mb-0">
                   ?????<br>
                </p>
                <h5>Abstract:</h5>
                <p class="text-black-50 mb-0 small">
                  ???
                </p> -->
                <br>
                <h5>Short Bio:</h5>
                <p class="text-black-50 mb-0 small">
                Lenka Zdeborová is a Professor of Physics and Computer Science at École Polytechnique Fédérale de Lausanne, where she leads the Statistical Physics of Computation Laboratory. She serves as an editorial board member for several prestigious journals, including the Journal of Physics A, Physical Review E, Physical Review X, SIMODS, Machine Learning: Science and Technology, and Information and Inference. Lenka's area of expertise lies in the application of statistical physics concepts such as advanced mean field methods and replica method to machine learning and optimization problems. She has a keen interest in erasing boundaries between theoretical physics, mathematics, and computer science. </p>
              </div>
            </div>
          </div>
          <div class="row no-gutters mb-4 mb-lg-5" id="jacob">
            <div class="col-xl-3 col-lg-2">
              <img class="img-fluid mb-3 mb-lg-0" src="img/jacob.png" alt="">
            </div>
            <div class="col-xl-9 col-lg-10">
              <div class="featured-text text-center text-lg-left">
                <h4>
                <a href="https://jsteinhardt.stat.berkeley.edu/" class="pagelink">
                   Jacob Steinhardt (University of California, Berkeley)
                </a></h4>
<!--                 <h5>Title:</h5>
                <p class="text-black-50 mb-0">
                 ????
                </p>
                <p>
                  <a href="https://slideslive.com/38922020/bridging-game-theory-and-deep-learning-1">Link to video</a>
                </p>
                <h5>Abstract:</h5>
                <p class="text-black-50 mb-0 small">
                 ???
                </p> -->
                <br>
                <h5>Short Bio:</h5>
                <p class="text-black-50 mb-0 small">
                 Jacob Steinhardt is an assistant professor of statistics at the University of California, Berkeley, with a research focus on making conceptual advances necessary for reliable and human value-aligned machine learning systems. His research areas include the robustness and security of machine learning systems, reward specification and learning human values, and scalable alighnment through studying the macroeconomic equilibria of such systems. Recently, he has also studied the science of deep learning. Beyond his technical research, Jacob collaborates with policy researchers on the use and misuse of machine learning, is a technical advisor to the \textit{Open Philanthropy Project} and writes a blog including forecasts for capabilities of future ML systems.
                </p>
              </div>
            </div>
          </div>
          <div class="row no-gutters mb-4 mb-lg-5" id="neel">
            <div class="col-xl-3 col-lg-5">
              <img class="img-fluid mb-3 mb-lg-0" src="img/neel.png" alt="">
            </div>
            <div class="col-xl-9 col-lg-7">
              <div class="featured-text text-center text-lg-left">
                <h4>
                <a href="https://www.neelnanda.io/" class="pagelink">
                 Neel Nanda (Independent Researcher)
                </a></h4>
<!--                 <h5>Title:</h5>
                <p class="text-black-50 mb-0">
                ???
                </p>
                <p>
                  <a href="https://slideslive.com/38922021/bridging-game-theory-and-deep-learning-2">Link to video</a>
                </p>
                <h5>Abstract:</h5>
                <p class="text-black-50 mb-0 small">
                 ???
                </p> -->
                <br>
                <h5>Short Bio:</h5>
                <p class="text-black-50 mb-0 small">
                  Neel Nanda is an independent researcher who focuses on the field of mechanistic interpretability, which involves reverse engineering the algorithms learned by a trained neural network. Previously, he worked as a language model interpretability researcher at Anthropic, under the supervision of Chris Olah. Prior to that, he completed an undergraduate degree in pure mathematics at Cambridge. Neel is passionate about addressing the issue of existential risk posed by powerful AI, which he considers to be one of the most crucial problems of this century.

                </p>
              </div>
            </div>
          </div>
          <div class="row no-gutters mb-4 mb-lg-5" id="elvis">
            <div class="col-xl-3 col-lg-3">
              <img class="img-fluid mb-3 mb-lg-0" src="img/elvis.png" alt="">
            </div>
            <div class="col-xl-9 col-lg-9">
              <div class="featured-text text-center text-lg-left">
                <h4>
                <a href="https://dohmatob.github.io/" class="pagelink">
                  Elvis Dohmatob (Meta AI)
                </a></h4>
                <br>
                <h5>Short Bio:</h5>
                <p class="text-black-50 mb-0 small">
                  Elvis Dohmatob is a researcher at FAIR (Meta AI) in Paris. His research focuses on theoretical and algorithmic aspects of trustworthy ML, the main themes being adversarial examples and more recently, efficient recommender systems under fairness constraints. That includes studying phase transitions in models' behaviour and understanding the fundamental tradeoffs between robustness, fairness, and accuracy.
                </p>
              </div>
            </div>
          </div>
          <div class="row no-gutters mb-4 mb-lg-5" id="ziming">
            <div class="col-xl-3 col-lg-3">
              <img class="img-fluid mb-3 mb-lg-0" src="img/ziming.png" alt="">
            </div>
            <div class="col-xl-9 col-lg-9">
              <div class="featured-text text-center text-lg-left">
                <h4>
                <a href="https://kindxiaoming.github.io/" class="pagelink">
                  Ziming Liu (MIT and IAIFI)
                </a></h4>
                <br>
                <h5>Short Bio:</h5>
                <p class="text-black-50 mb-0 small">
                  Ziming Liu is a Physics PhD student at MIT and IAIFI, advised by Prof. Max Tegmark. His research is focused on the intersection of artificial intelligence and physics, including but not limited to (1) AI for physics: extracting physical insights (e.g. conservation laws and symmetries) from data, improving prediction accuracy and sampling efficiency for data analysis in physics. (2) Physics for AI: developing effective theories to understand the dynamics and generalization of neural networks, and building physics-inspired machine learning models. Before that, Ziming received his Bachelor's degree in physics from Peking University.
                </p>
              </div>
            </div>
          </div>

        </div>
      </section>


      <!-- CFP Section -->
      <section id="CFC" class="about-section text-center">
        <div class="container">
          <div class="row">
            <div class="col-lg-8 mx-auto">
              <h4 class="text-white-75"> Call for Papers</h4>
              <p class="text-white-75">We invite submissions that explore any of the questions below, or alternatively, any question related to the emerging phenomena in deep learning. We also highly value any work that identifies new relevant research directions.

              <ul class="text-white-75 text-justify">
              <li>What are the underlying mechanisms and principles that govern the behavior of machine learning models? </li>
              <li>When and under what conditions can scaling laws be applied to machine learning models?</li>
              <li>What are the critical behaviors of machine learning models near phase transitions, and how can these behaviors be explained and predicted?</li>
              <li>Can we find progress measures that underlie sudden performance improvements?</li>
              <li>What are the future directions and opportunities for research in emergent phenomena in machine learning, and how can this research contribute to the development of more robust and generalizable machine learning models?</li>
              
            </p>
              <h4 class="text-white-75"> Submission details </h4>
              <p class="text-white-75 text-lg-left">
                To submit a paper, please prepare an anonymous extended abstract in PDF format, using the ICML style modified as per our guidelines. The abstract should be between 2 to 4 pages in length, excluding references. We will be using CMT for the submission process. If your work has been previously published or is currently under review, you may still submit it, but please indicate clearly that it is published work when submitting. Your submission may be considered for a contributed talk, spotlight, or poster presentation, and all accepted submissions will be displayed as posters. The deadline for submitting extended abstracts is ??? (11:59pm AoE). Please note that final versions of the abstracts will be made available on the workshop website, and while they are archival, they do not constitute proceedings.
              </p>
              <h2 class="text-white mb-4">Key Dates:</h2>
              <ul class="list-group">
                <li class="list-group-item list-group-item-dark">Abstract submission deadline: ???? CMT link?</li>
                <li class="list-group-item list-group-item-dark">Acceptance notification: ????</li>
              </ul>
            </div>
          </div>
        </div>
      </section>
      
      <section id="Committee" class="projects-section bg-light">
        <h2 class="text-black mb-4 text-center">Organizers</h2>
        <div class="container">
            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/irina.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Irina Rish (Mila & University of Montreal)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Irina Rish is a Full Professor in the Computer Science and Operations Research Department at the Université de Montréal (UdeM). She holds a Canada Excellence Research Chair (CERC) in Autonomous AI and a Canadian Institute for Advanced Research (CIFAR) Canada AI Chair. Dr Rish received her MSc and PhD in AI from University of California, Irvine and MSc in Applied Mathematics from Moscow Gubkin Institute. Irina has extensive experience organizing workshops.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/guillaume.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Guillaume Dumas (Mila & University of Montreal)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Guillaume Dumas is an associate professor in computational psychiatry at the Faculty of Medicine at the University of Montréal and the director of the Precision Psychiatry and Social Physiology (PPSP) laboratory at the CHU Sainte-Justine Research Center. He holds the IVADO Chair in "AI and Mental Health,"  the FRQS J1 Fellowship in "AI and Digital Health,"  and is an appointed academic member of Mila – Quebec Artificial Intelligence Institute.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/mohammad.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Mohammad Pezeshki (Meta AI)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Mohammad Pezeshki is a post-doc researcher at FAIR (Meta AI). His research is concerned with understanding learning and generalization in neural networks using tools from dynamical systems and statistical physics. Prior to joining Meta, he obtained his PhD from Mila at Université de Montréal.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/hattie.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Hattie Zhou (Mila & University of Montreal)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Hattie Zhou is a PhD student at Mila and the University of Montréal, and previously worked as a student researcher at Google Brain. Her research interests revolve around understanding and improving generalization in neural networks from an empirical perspective. She is especially interested in reasoning and systematic generalization in large language models.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/gabriela.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Gabriela Moisescu-Pareja (Mila & McGill University)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Gabriela Moisescu-Pareja is a Master's student in Computer Science at McGill University, with a background in pure mathematics. She is interested in hierarchical reinforcement learning, the theoretical foundations (and empirical science) of deep learning, and ML applied to scientific discovery. Previously, she was an ML research engineer at Valence Discovery and an intern at Google.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/pascal.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Pascal J. Tikeng Notsaw (Mila & University of Montreal)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Pascal J. Tikeng Notsawo is a first year Master's student in Computer Science at the University of Montréal, and a research student at Mila, where he is working on understanding the generalization phenomenon in deep learning from a dynamical systems perspective. Pascal also holds a master of engineering in computer science from the National Advanced School of Engineering Yaounde.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/ethan.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Ethan Caballero (Mila & University of Montreal)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Ethan Caballero is a PhD student at Mila. He is interested in finding all the downstream evaluations/measurements that matter and finding that which scales best according to all those downstream evaluations simultaneously, primarily in the largest scale regime; these interests encompass all aspects of artificial neural networks. Prior to that, he mostly worked on out-of-distribution generalization and generalization theory.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/adam.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Adam Ibrahim (Mila & University of Montreal)
                  </h4>
                  <p class="text-black-50 mb-0">
                    Adam Ibrahim is a PhD student at Mila and the University of Montréal, where he works on optimization, generalization and robustness of neural networks. Before joining Mila, Adam has done research in Human-computer interaction at UC Santa Barbara, and theoretical physics at McGill University. Recently, Adam was co-organizer of the 4th Neural Scaling Laws workshop colocated with NeurIPS 2022.
                  </p>
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/mathilde.png" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Mathilde Besson (EDI Coordinator - CERC A.AI)
                  </h4>
<!--                   <p class="text-black-50 mb-0">
                    bio
                  </p> -->
                </div>
              </div>
            </div>

            <div class="row no-gutters mb-4 mb-lg-5">
              <div class="col-xl-3 col-lg-3">
                <img class="img-fluid mb-3 mb-lg-0" src="img/rachade.jpg" alt="">
              </div>
              <div class="col-xl-8 col-lg-8">
                <div class="featured-text text-center text-lg-left">
                  <h4>
                  Rachade Hmamouchi (Senior Coordinator - CERC A-AI
                  </h4>
                  <p class="text-black-50 mb-0">
                    Rachade Hmamouchi, with a background in bioinformatics, is not only an entrepreneur and business advisor, but also a passionate advocate of science and technology. She frequently gives talks at various conferences and leads workshops on a diverse range of topics including artificial intelligence, genetics, coding, technology in healthcare, and entrepreneurship.
                  </p>
                </div>
              </div>
            </div>

          </section>



        <!-- Footer -->
        <footer class="bg-black small text-center text-white-50">
<!--           <div class="container">
            Address: Hawaii, right corner
          </div> -->
        </footer>
        <!-- Bootstrap core JavaScript -->
        <script src="vendor/jquery/jquery.min.js"></script>
        <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
        <!-- Plugin JavaScript -->
        <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
        <!-- Custom scripts for this template -->
        <script src="js/grayscale.min.js"></script>
      </body>
    </html>
